Cool — you’re basically describing a discrete-time “factory” loop for a monorepo, where work only advances at turn boundaries, and everything cross-service travels through a durable message layer (your “issues/beads”). That’s a really strong way to keep multi-agent systems from degenerating into chaotic, half-coordinated edits.

Below is a concrete design that fits what you said and maps cleanly onto the Microforge shape you already have (cells + builder/monitor/reviewer + manager + optional architect, Beads-backed, tmux sleep/wake).

⸻

Core concepts

Cells and scopes
• Cell = a subfolder (microservice/module) scope — e.g. services/payments/\*
• Each cell owns a triad:
• Builder: can write only in-scope
• Reviewer: read-only; enforces quality + tool discipline + “no corner cutting”
• Monitor: read-only; turns runtime + CI + telemetry signals into new work
• Manager: global triage + scheduling + turn orchestration
• Merge Manager: integrates PRs at end-of-turn + builds images + ships to a staging/prod lane
• Architect (optional but powerful): cross-service contracts, docs, interface coherence, “stop breaking each other”

“Beads”: the communication primitive (issues-as-a-bus)

Treat every cross-boundary communication as a bead, backed by the Beads CLI (`bd`) and its `.beads/` repo data.

Beads should be small, typed, and linkable, so they chain into threads.

Bead types
• ChangeRequest: “please change X in your module”
• ContractProposal: “I need an API/schema change; here’s a compat plan”
• Observation: “monitoring found regression/anomaly”
• Decision: “need human/architect decision”
• MigrationStep: “do step N of rollout plan”

Bead fields (minimum viable)
• id, type, status, priority
• metadata in description front-matter:
  - cell, role, scope, turn_id
  - severity, source_role
  - inbox, outbox, promise, worktree (for assignments)
• acceptance_criteria / compat_notes / links in body

This “bead bus” is what keeps the system sane: agents never DM each other, they leave structured beads that get triaged and scheduled into the next turn.

⸻

The turn loop (a full cycle)

Think of each turn as a “tick” where the repo advances one step, with clean gates.

0. Intake snapshot (start of turn)

Manager gathers:
• new beads from last Monitoring turn
• any human-submitted priorities
• backlog beads not yet accepted

Output: a ranked “turn slate” of beads to attempt this turn.

1. Triage + assignment (Manager + Architect)

Manager:
• assigns beads to cells (and splits big beads)
• resolves obvious dependency ordering (e.g. contract first, feature second)
Architect (if enabled):
• flags contract-breaking changes
• enforces “compat plan required” for cross-service changes

Output: Assignments(turn_id) for each cell triad.

2. Agent work phase (Builder turns)

Each cell’s Builder wakes and executes:
• pulls latest main
• selects assigned beads
• implements in-scope changes
• if needs out-of-scope work: emits new ChangeRequest/ContractProposal beads to other cells (and stops—no cowboy edits)
• opens PR tagged with turn_id, cell, and linked beads

Output: PRs ready for review, plus new beads for other cells.

3. Review phase (Reviewer turns)

Reviewer per cell:
• checks PR against acceptance criteria + style + tests
• ensures the builder didn’t:
• expand scope
• silently change contracts
• paper over failures
• either:
• approves → labels PR ready-to-merge
• requests changes → comments + re-queues bead

Output: approved PR set (and any “fixup” beads).

4. End-of-turn integration (Merge Manager)

Merge Manager:
• merges only PRs that are:
• approved by reviewer
• green on CI
• compatible with current turn’s contract gates
• if conflicts arise:
• creates a bead ConflictResolution owned by the relevant cell
• produces a Turn Release Notes artifact (auto-generated)

Output: merged main at turn_id, release notes.

5. Build/images (post-merge)

Pipeline:
• builds images for touched services
• tags artifacts with turn_id and commit SHA
• deploys to a lane (at least staging)

Output: build artifacts + deployment record.

6. Monitoring turn (after deploy)

Monitors wake (global and/or per cell):
• run:
• smoke/integration tests
• synthetic checks
• canary analysis
• log anomaly scans
• SLO regression checks
• for each signal → emits Observation beads to owning cells
• if severe → emits Decision bead for human + “stop the line” suggestion

Output: new beads that become the next turn’s inputs.

7. Human-in-the-loop digest (end of every turn)

Human receives a summary that’s consistent and scannable:

Turn Digest format
• What merged (PRs grouped by cell)
• Why (beads closed)
• Risk (compat changes, migrations, performance shifts)
• What broke / regressed (new Observation beads)
• Decisions needed (human/architect)
• Next turn slate preview (top queued beads)

This is the single best lever for trust: humans don’t need to read everything, but they always know what changed and why.

⸻

The critical rule that makes cross-service work not suck

“No out-of-scope edits. Ever.”
Cross-service changes are negotiated via beads with a compat plan.

To make that workable, require a Contract Proposal bead whenever an API/schema/shared-library interface changes.

Contract Proposal must include
• current behavior
• proposed behavior
• compatibility strategy:
• additive first
• dual-read/dual-write if needed
• deprecation window
• acceptance tests / contract tests
• rollout steps (often multiple turns)

This turns “please update service B” from chaos into a predictable pipeline.

⸻

Guardrails that prevent multi-agent meltdown

Turn invariants
• No merges mid-turn (unless you define a “hotfix mini-turn” lane)
• Only Merge Manager merges to main
• Monitoring only generates beads; it doesn’t fix code
• Reviewer is the “quality firewall” (and has veto power)

Rate limits / sanity controls
• Cap beads created per cell per turn (prevents spam)
• Require acceptance criteria (prevents vague tickets)
• Auto-close stale beads only with a reason + label

Escalation paths
• Stop-the-line: Monitoring emits Decision(sev=critical) → blocks next merge turn until acknowledged
• Hotfix lane: a separate “emergency turn” with tighter scope and immediate monitoring

⸻

How this maps onto your Microforge repo (cleanly)

You already have:
• Beads-backed state (via `bd`)
• cells/agents/tasks/assignments modeled as beads
• tmux wake/sleep
• hooks-driven fetch/pause

What you add to support this “turn economy”:

Minimal bead types + conventions
• turn: tracks the active turn (stored in `~/.microforge/rigs/<rig>/turn.json`)
• task: unit of work, scoped to a cell
• assignment: a task bound to a role/cell with inbox/outbox + promise
• request / observation / decision / contract: cross-cell coordination

Hook/manager behavior
• Stop hook claims the next ready assignment bead (type=assignment) for the active cell/role.
• Manager tick closes assignment beads when the promise token appears in the outbox.

Minimal commands
• mforge turn start|status|end
• mforge bead create|list|show|close
• mforge request create|list|triage (thin wrappers over beads)
• mforge manager tick (reconciliation)
• mforge monitor run-tests (emit observation beads)

Optional: a sync adapter to mirror beads to GitHub/GitLab issues (so humans can live in the tracker UI).

⸻

A concrete example turn (what this feels like)

Turn 42 goal: add customer_tier to Orders and propagate to Billing. 1. Manager assigns:

    •	Orders: ContractProposal + add field (backward compatible)
    •	Billing: “consume field once available”

    2.	Orders Builder:

    •	adds field + defaults + emits schema version
    •	opens PR, links bead

    3.	Orders Reviewer:

    •	checks contract tests + ensures additive change

    4.	Merge Manager merges Orders PR, builds image, deploys
    5.	Monitoring turn:

    •	sees increased 5xx in Billing due to unexpected null handling
    •	emits Observation bead to Billing

    6.	Human digest:

    •	“Orders added field (safe). Billing regressed on null path (needs fix). Next turn: Billing null safety + canary.”

That’s exactly the behavior you want: fast progress, regressions turn into beads, next turn picks them up deterministically.

⸻

Illustration: 3 turns in a turn-based "agent engine"

Legend:
- MGR = Manager (triage + assign)
- ARC = Architect (docs + cross-service coherence)
- Cell:PAY = Payments cell triad (Builder / Monitor / Reviewer)
- Events are posted to a queue; nothing calls anything else directly.

Turn 12 (feature work starts)

[Turn 12: Intake]     Events: [FeatureRequest:/healthz in payments]
        |
        v
[Turn 12: Plan]       MGR creates Task T-901, assigns to PAY.B
                      ARC creates DocTask D-55 (API note)
        |
        v
[Turn 12: Execute]    PAY.B applies code changes + adds tests
                      PAY.R reviews diff; flags "missing negative test"
                      PAY.M runs scoped test suite; all green
        |
        v
[Turn 12: Review]     Log + snapshot:
                      - PAY.B produced PR #221
                      - PAY.R -> Request: Add negative test
                      - PAY.M -> OK
                      Events emitted: [ReviewRequest:AddNegativeTest]

Turn 13 (review feedback becomes work)

[Turn 13: Intake]     Events: [ReviewRequest:AddNegativeTest]
        |
        v
[Turn 13: Plan]       MGR converts request -> Task T-902, assigns to PAY.B
        |
        v
[Turn 13: Execute]    PAY.B adds negative test + updates docs stub
                      PAY.R re-checks; approves
                      PAY.M runs tests; one flaky test in payments appears
        |
        v
[Turn 13: Review]     Log:
                      - PAY.R -> Approved
                      - PAY.M -> MonitorRequest: Flaky test detected
                      Events: [MonitorRequest:InvestigateFlake]

Turn 14 (monitor-driven reliability work)

[Turn 14: Intake]     Events: [MonitorRequest:InvestigateFlake]
        |
        v
[Turn 14: Plan]       MGR creates Task T-903 (fix flake), assigns PAY.B
                      ARC updates cross-service checklist doc
        |
        v
[Turn 14: Execute]    PAY.B identifies race, stabilizes test, adds retry guard
                      PAY.R enforces "no retry hiding bug" rule; requests root-cause note
                      PAY.M validates metrics/test stability
        |
        v
[Turn 14: Review]     Log + snapshot:
                      - Regression prevented by reviewer gate
                      - Monitor confirms stability trend
                      Events: [DocUpdateNeeded:RootCauseSummary]

What matters (game-engine style)
- Deterministic phases: Intake -> Plan -> Execute -> Review.
- Event queue: systems publish events; no direct calls between roles.
- Commands/tasks: planning produces commands executed in a later phase.
- End-of-turn checkpoint: logs + snapshots gate the next turn.

Pseudo engine skeleton (turn-based orchestration loop)

```text
class Event: pass
class Command: pass

class EventBus:
  queue = []
  def publish(event): queue.append(event)
  def drain(): events, queue = queue, []; return events

class Engine:
  order = [manager, architect, builder, reviewer, monitor]
  def run_turn(turn_id):
    log = TurnLog(turn_id)
    intake = bus.drain()
    planned = []
    for role in order:
      planned += role.plan(state, intake, log)
    emitted = []
    for cmd in planned:
      emitted += cmd.actor.execute(state, cmd, log)
    for e in emitted:
      log.emit(e)
      bus.publish(e)
    snapshot = checkpoint_repo_state()
    log.record("ENGINE", f"Checkpoint: {snapshot}")
    return log
```

Microforge mapping
- Event queue -> beads (bd) + request/observation/decision types
- Plan phase -> manager tick creates tasks/assignments
- Execute phase -> agent hooks run assigned work
- Review phase -> reviewer/monitor emit new beads for next turn
- Checkpoint -> turn snapshot + digest output

⸻

If you want one “extra spicy” enhancement

Add a notion of Action Points per turn:
• each Builder can spend, say, 3 AP:
• 1 AP = small refactor / bugfix
• 2 AP = medium feature / migration step
• 3 AP = contract change (forces reviewer + architect gate)

It gives you a natural throttle and makes the system “game-like” in a good way: predictable throughput, fewer giant risky turns.

⸻

Beads (`bd`) is the current source of truth; add issue-sync later if you want humans working from GitHub/GitLab.
